% Point 1: reporting the specific content of your game manipulation makes
%  1 - The experiment replicable
%  2 - The results more reproducible
%  3 - Eases interpretation in reading & aggregating work (e.g. meta-analysis)
%  4 - cutscenes and tutorials and shit
% Point 2: examining the content experienced in a game for better mediational models
%  1 - Manipulation checks: You know that the manipulation worked and that subjects on average experienced the intended content
%  2 - Quality control: You can exclude subjects who played the wrong condition or didn't engage in the correct behavior
%  3 - Mediational models: You can see which in-game actions, contents, etc are responsible for which outcomes. Does playing worse lead to more frustration and greater aggression? Does an in-game immoral choice inspire players to be more moral IRL? Does the effect differ for players who did XYZ?

\title{Suggestions for Improved Stimulus Reporting and Manipulation Checks in Video Game Research}

 “Writing about music is like dancing about architecture.” – Marty Mull (uncertain: http://quoteinvestigator.com/2010/11/08/writing-about-music/)
Current Problems 

Research in violent video game effects on aggressive outcomes is a controversial field. Part of this controversy stems from differing results across research teams. Some teams are able to (conceptually) replicate the effect, while other teams do not observe the effect. These differences have become somewhat personal recently, as \citet{Greitemeyer:Mugge:2014} present meta-analytic results demonstrating differing effect size estimates across research teams, suggesting that certain researchers aren't ``doing it right''. %I don't want to get into a mudfight here so this will need editing.

% Consider "replicable / replicability" vs "reproducible / reproducibility"
This controversy could be alleviated if research were more replicable across research teams. Replicability of research has been the focus of much recent attention and work. These reproducibility initiatives have emphasized the importance of preregistration of studies, open availability of data, and the open availability of research materials. %Research that meets these criteria is more replicable, and therefore, more convincing, and more likely to reflect true phenomena.
It is this last point, the availability of research materials, that is the focus of the current manuscript. In conventional psychological research, open materials means making available the questionnaires, measures, manipulations, and computer scripts necessary to perform a close replication of the experiment. It is well-understood that the methods and materials of experiments are rarely described with sufficient precision to permit such a close replication, but when this precision is available, the quality and replicability of the research is improved. 

% Point 1: reporting the specific content of your game manipulation makes
%  1 - The experiment replicable
%  2 - The results more reproducible
%  3 - Eases interpretation in reading & aggregating work (e.g. meta-analysis)
%  4 - cutscenes and tutorials and shit
We see special challenges in describing the content of video game manipulations. Video games are complex stimuli. Video games are interactive, and so the content provided to the subject may vary from subject-to-subject and from session-to-session. Video games are an artistic medium, and so their contents may be challenging to quantify. % <-- less strong point?


At present, descriptions of game stimuli in video game research are often insufficient to permit a replication. Researchers often provide little more than a name, which is especially unfortunate in the case that the game name is indistinct and difficult to find via web search (e.g. “Penguins” \citep{(Greitemeyer:2014} or “Austin Powers” \citep{Bushman:Anderson:2002}). This obfuscates the nature of the game and impairs communication to the reader.

This practice allows reviewers and readers to assess and evaluate whether the stimulus is appropriate to the experimental condition. 

It should also be mentioned whether subjects were permitted or assisted in configuring the controls. Inappropriately configured controls may thwart feelings of competence and lead to increases in aggressive outcomes \citep{Przybylski:etal:2014}, leading to nuisance variance in the dependent variable, thereby diminishing the observed effect size and power of prediction. One common control configuration that must be made between players is orientation of the y-axis. In first-person games, the player uses a mouse or joystick to orient the first-person perspective. The y-axis of the mouse or joystick determines the angle of the player's perspective, looking and aiming higher or lower. Some players find a ``normal'' y-axis to be most intuitive: pushing the mouse or joystick away moves the crosshair upwards. However, other players find an ``inverted'' y-axis to be more intuitive, in which pushing the mouse or joystick away moves the crosshair downwards. These preferences are often stable and strong, and players made to use the other y-axis setting may find the experience particularly awkward and frustrating, much as a right-handed person asked to write left-handed might feel.

There are also no standards for reporting the portion of game content experienced. A single video game often contains many hours’ worth of content, with many different levels, missions, game modes, and optional settings. All of these conditions may be potentially important to the manipulation, and failures to reproduce any of these conditions may lead to failures of replication. For example, many popular video games also begin with an hour or more of tutorials, cutscenes, and dialogue. In the case that the player is put in front of the game and the game started from the very beginning, it is actually quite unlikely that the player will even finish watching the opening movie sequences within fifteen minutes! On the other hand, if the experiment skips the beginning cutscenes, the player may not understand the context of his or her in-game actions --- a particular risk to studies of prosocial games. Similarly, if the experiment skips the tutorial, the player may not learn the controls appropriately. 

Because games are interactive, players may also have the opportunity to choose which content they experience and how their avatar behaves. For example, popular “open-world” games such as Grand Theft Auto, Red Dead Redemption, or The Elder Scrolls V: Skyrim allow players an open world composed of many possible activities. While violence is perhaps the most common of these activities, it is not impossible that some players may spend the entire play session engaged in a lawful and non-violent pastime such as bowling or horseback riding.

The above ambiguities make it difficult to determine the exact game content that participants experience in most studies. This uncertainty makes it difficult to evaluate and replicate other researchers' work. It also obscures the presence of game contents besides violent content, glossing over potential confounds and moderators.

It is also sometimes unclear as to whether experimental manipulations are successful across all participants. First, not all subjects may experience the game as intended. Some participants may quickly understand the controls, while other participants may fail to understand the basic rules of play or otherwise fail to engage with the experimental manipulation. Some participants may disregard the instructions of the experimenter or even the game itself in order to interact with the software in their own way. Second, aggression research frequently involves deception, which does not always work on participants. It is often unclear as to whether the deception was effective on all subjects, or if some subjects were wise to the deception. In the latter case, it is often not clear what was done with these subjects. While some research projects report testing for suspicion and an exclusion of subjects who were not deceived, many studies still do not report any such test or what would be done with the data of participants failing such a test. It cannot be assumed that non-deceived participants exhibit representative levels of aggression; even if they did, it would seem to bode ill for the validity of the dependent variable.

\section{Report Everything}
When reporting a video game manipulation, it is helpful to describe everything necessary to replicate the conditions of the study. 

Does the game start from the very, very beginning? Are the opening cutscenes skipped? Is the tutorial skipped?
If players are starting from a particular save file, consider sharing the save file, if possible. Otherwise, name the particular level or section played.
Were the players taught the controls? If so, was it by tutorial, or by the experimenter? 

Provide your stimuli. As a service to collaborators, reviewers, and readers, we suggest that researchers either publish or link relevant video footage of all games used in game manipulations. As luck would have it, there exist many tools and websites for creating and distributing video footage of gameplay. Websites such as YouTube.com, Vimeo.com, and Twitch.TV are already used by thousands of hobbyists to record and broadcast footage. If relevant footage of the game is not already available, researchers can record their own using screencapture video software such as OpenBroadcasterSoftware (obsproject.com) or FRAPS (www.fraps.com). Including links to such footage makes it easier for your reviewers and readers to assess the content (both graphical and ludological) of your game manipulation. Authors are encouraged to footnote any mentioned game with a video link, when appropriate. 
Be as specific as possible in naming the video game. Keep in mind that video games often come in franchises, and that separate entries in a franchise may differ by as little as a subtitle (e.g. Red Faction, Red Faction: Armageddon) or a year of publication (e.g., Tomb Raider (1996), Tomb Raider (2013)). If the game is on a website, link the website at which it can be played, but keep in mind that hyperlinks may rot over time, and so a hyperlink is not sufficient by itself to document the manipulation.

% Point 2: examining the content experienced in a game for better mediational models
%  1 - Manipulation checks: You know that the manipulation worked and that subjects on average experienced the intended content
%  2 - Quality control: You can exclude subjects who played the wrong condition or didn't engage in the correct behavior
%  3 - Mediational models: You can see which in-game actions, contents, etc are responsible for which outcomes. Does playing worse lead to more frustration and greater aggression? Does an in-game immoral choice inspire players to be more moral IRL? Does the effect differ for players who did XYZ?
\subsection{Observe and report player behavior} In experimental psychology, it is common to perform a manipulation check to assess the degree to which an experimental manipulation has had the intended effect. When studying games, it is similarly important to observe player behavior and performance, as this can indicate whether your participants are appropriately perceiving and interacting with the game as intended. Gameplay variables thereby often represent potentially-important mediator variables.

Gameplay variables may also represent individual differences among your players. If one player as compared to the rest of the sample clears more stages, suffers less damage per stage, and earns more points per stage, it can be inferred that player is more skilled than most. Conversely, if another player demonstrates extremely poor progress towards the game’s goal, it can be inferred that the player has failed (to some degree) to understand the controls and strategy, invest sufficient effort, and/or experience the intended game content. 

The collection and analysis of these variables is often quite easy thanks to the computerized nature of these games. For example, many games automatically keep track of score, accuracy of attacks, and other gameplay variables. In the event that these variables are not measured and provided, it is often possible to modify the game’s scripts to track these variables. One open-source game maniuplation (Hilgard, 2014) tracks the number of times the player died, the number of monsters slain, the player’s furthest progress through the game, the number of bullets fired with each weapon, and the total number of times the player has been hit. These measures help to identify experimental failures, such as if the subject decided to run past all the monsters instead of fight them, ignored the game, or failed to learn the controls or rules of the game.

Observing the player’s in-game behaviors may also yield new insights to the mechanisms of the effects of game manipulations. Through observing the interaction between player and the player-dependent game content, researchers can peer inside the black box of game manipulations. This may help to answer persistent questions of who is affected, how, and why.

We urge researchers to use these gameplay variables in analysis to test for alternative hypotheses, failures of random assignment, and for other effects of subject. However, we caution against the use of in-game behavior as a measure of aggression in itself, as these behaviors are more likely to be motivated by strategic concerns, and thus unlikely to have external validity in predicting real-world aggression. We would not say that a Chess player who preserves his bishops but sacrifices his queen has positive attitudes towards religion and negative attitudes towards women! Thus, a tendency for players to use a sword instead of martial arts to kill an opponent (Barlett et al., 2008) or to use weapons instead of stealth (Anderson & Morrow, 1995; Panee & Ballard, 2002) are unlikely to represent changes in real-world aggression. (Note, however, that Barlett et al. still found significant effects on other, more valid, measures of aggressive arousal and cognition.)
	
Always test subjects for suspicion and report any exclusions. It cannot be assumed that all subjects were naïve to the study hypotheses, nor can it be assumed that the inclusion of non-naïve participants does not alter the observed effect. Researchers must test participants for failures of deception and report any exclusions made for this reason . Ideally, the field would decide upon a standardized procedure for screening and including or excluding participants.

\section{Applications}
These improved reporting standards will yield greater transparency in communicating research materials between researcher and reader. Thus, the entire breadth of differences between game conditions will be clearly communicated. Furthermore, observing player behavior during gameplay will provide additional insights into the behaviors, cognitions, and emotions brought about by game manipulations, as well as indicate when the manipulations fail. This will improve the efficacy of manipulations, the precision and reliability of effect size estimates, the replication of manipulations across laboratories, and the opportunities to observe mediating variables .
